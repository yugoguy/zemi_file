{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bf3f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(vcf_path, choice=True):\n",
    "    #imports and classification dataframe preparation\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    import requests\n",
    "    import matplotlib.pyplot as plt\n",
    "    if choice: \n",
    "        print(\"dataframe used in this code can be updated.\")\n",
    "        print(\"if you have already updated the dataframe recently using this code, it is recommended not to update since it should be already updated.\")\n",
    "        print(\"by default, last update is 2023/12/18\")\n",
    "        print(\"please note that updating the dataframe can take time (5~30min)\")\n",
    "        update_ybrowse = input(\"update the dataframe? (y/n)\")\n",
    "        if update_ybrowse==\"y\":\n",
    "            update_ybrowse=True\n",
    "        else:\n",
    "            update_ybrowse=False\n",
    "        if update_ybrowse:\n",
    "            print(\"updating ISOGG Ybrowse SNP index. it may take several minutes to update!\")\n",
    "            isyb = pd.read_csv(\"https://ybrowse.org/gbrowse2/gff/snps_hg38.csv\")\n",
    "            isyb.to_csv(\"snps_hg38.csv\")\n",
    "        else:\n",
    "            isyb = pd.read_csv(\"snps_hg38.csv\", header=0)\n",
    "        print(\"basic dataframe for analysis is ready!\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        #considering implementation\n",
    "        \"\"\"\n",
    "        print(\"this code also use extra dataframe extracted from YFull.\")\n",
    "        print(\"this dataframe can be updated too.\")\n",
    "        print(\"if you have already updated the dataframe recently using this code, it is recommended not to update since it should be already updated.\")\n",
    "        print(\"by default, last update is 2023/12/18\")\n",
    "        print(\"please note that updating the dataframe can take time (5~30min)\")\n",
    "        update_yfull = input(\"update the extra dataframe? (y/n)\")\n",
    "        if update_yfull==\"y\":\n",
    "            update_yfull=True\n",
    "        else:\n",
    "            update_yfull=False\n",
    "        if update_yfull:\n",
    "            print(\"updating YFull SNP index. it may take several minutes to update!\")\n",
    "            htmlraw = requests.get(f\"https://www.yfull.com/snp-list/?page={1}\")\n",
    "            content = pd.read_html(htmlraw.content, header=0)\n",
    "            YFull = content[1]\n",
    "            page = 2\n",
    "            while True:\n",
    "                try: \n",
    "                    htmlraw = requests.get(f\"https://www.yfull.com/snp-list/?page={page}\")\n",
    "                    content = pd.read_html(htmlraw.content, header=0)\n",
    "                    current = content[1]\n",
    "                    YFull = pd.concat([YFull,current])\n",
    "                    page+=1\n",
    "                except ValueError:\n",
    "                    break\n",
    "            YFull.to_pickle(\"YFull_updates.sav\")\n",
    "        else:\n",
    "            YFull = pd.read_pickle(\"YFull_updates.sav\")\n",
    "        yfull = YFull[[\"SNP-ID\", \"Build38\", \"ANC\", \"DER\", \"Branch\"]]\n",
    "        yfull.columns = [[\"SNP-ID\", \"pos38\", \"ref\", \"var\", \"branch\"]]\n",
    "        print(\"extra dataframe for analysis is ready!\")\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        isyb = pd.read_csv(\"snps_hg38.csv\", header=0)\n",
    "        YFull = pd.read_pickle(\"YFull_updates.sav\")\n",
    "    \"\"\"\n",
    "    # vcf file preparation\n",
    "    vcf = pd.read_table(vcf_path, header=None)\n",
    "    vcfy = vcf[vcf[0]==\"chrY\"]\n",
    "    var = vcfy[[1,2,3,4]]\n",
    "    var.columns = [[\"GRCh38pos\" ,\"rs\", \"ref\", \"var\"]]\n",
    "    \n",
    "    # find matches\n",
    "    matched = pd.DataFrame()\n",
    "    for i in range(len(var)):\n",
    "        print(i)\n",
    "        varpos = var.iloc[i][\"GRCh38pos\"]\n",
    "        varvar = var.iloc[i][\"var\"]\n",
    "        df = isyb[(isyb[\"start\"]==varpos)&(isyb[\"allele_der\"]==varvar)]\n",
    "        matched = pd.concat([matched,df[[\"ID\",\"YCC_haplogroup\",\"ISOGG_haplogroup\", \"start\", \"allele_der\"]]])\n",
    "        \n",
    "    plt.bar(height=matched.ISOGG_haplogroup.value_counts().tolist()[0:20], x=matched.ISOGG_haplogroup.value_counts().index[0:20])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"number of prediction per ISOGG haplogroup (duplicate variant not considered)\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.bar(height=matched.YCC_haplogroup.value_counts().tolist()[0:20], x=matched.YCC_haplogroup.value_counts().index[0:20])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"number of prediction per YCC haplogroup (duplicate variant not considered)\")\n",
    "    plt.show()\n",
    "    \n",
    "    alt_dup = matched.drop_duplicates(subset=[\"start\", \"allele_der\"])\n",
    "    plt.bar(height=alt_dup.ISOGG_haplogroup.value_counts().tolist()[0:20], x=alt_dup.ISOGG_haplogroup.value_counts().index[0:20])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"number of prediction per ISOGG haplogroup (duplicate variant deleted)\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.bar(height=alt_dup.YCC_haplogroup.value_counts().tolist()[0:20], x=alt_dup.YCC_haplogroup.value_counts().index[0:20])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"number of prediction per YCC haplogroup (duplicate variant deleted)\")\n",
    "    plt.show()\n",
    "\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f642d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant is created with gpt-4-0613 model with following instruction: You are a professional data analyst. You are also Professional in genetics especially about Y chromosome haplogroups. You are professional in visualizing the given information. You always answer with visualization you are asked for, and also with text explaining the haplogroup in given list. Always give further explanations on the regions for top haplogroups, and be very specific about regions/ethnicity/era if possible.\n",
    "\n",
    "def get_gpt_output(matched, apikey):\n",
    "    from openai import OpenAI\n",
    "    from openai.types.beta.threads import MessageContentImageFile, MessageContentText\n",
    "    import matplotlib.image as mpimg\n",
    "    print(\"please note that this imformation is generated by GPT model, so accuracy is not guranteed.\")\n",
    "    print(\"for better informtion, please view following links.\")\n",
    "    print(\"https://yhrd.org/pages/resources/ysnps\")\n",
    "    print(\"https://www.familytreedna.com/public/y-dna-haplotree\")\n",
    "    print(\"https://www.yfull.com/tree/\")\n",
    "    print(\"https://en.wikipedia.org/wiki/Human_Y-chromosome_DNA_haplogroup\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    haplogroup = [i for i in result.ISOGG_haplogroup.value_counts().index if i not in [\"unknown\", \"not listed\"]][0:10]\n",
    "    count = [i for i in result.ISOGG_haplogroup.value_counts().tolist() if i not in [\"unknown\", \"not listed\"]][0:10]\n",
    "\n",
    "    prompt1 = f\"\"\"\n",
    "    top 10 haplogroups:\n",
    "    {haplogroup}\n",
    "    corresponding number of prediction (in same order with top 10 haplogroup):\n",
    "    {count}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt2 = \"\"\"\n",
    "    State top 3 region candidates of this individual's Y chromosome origin for each haplogroups listed as \"top 10 haplogroups\". Then output one integrated world map (using geopandas)  indicating those regions. The color intensity of the region in world map should be proportional to the corresponding number of prediction.\n",
    "\n",
    "    example code: (do not just duplicate, especially for choice of regions)\n",
    "\n",
    "    import geopandas as gpd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Haplogroup data and corresponding prediction numbers\n",
    "    haplogroups = [\n",
    "        'O1b1a1a2a-F5506/SK1665', 'O2a1c1a1a1a1g', 'R1b1a2a1a1d1', 'R1b1a2a1a2b1b', \n",
    "        'LT', 'C2b*', 'A00b', 'O1b1a1a2a-F5506/SK1661', 'D1a1a2-F1070', 'BT'\n",
    "    ]\n",
    "    predictions = [2300, 1100, 654, 435, 207, 150, 103, 90, 45, 10]\n",
    "\n",
    "    # Mapping haplogroups to their top 3 regions\n",
    "    haplogroup_regions = {\n",
    "        'O1b1a1a2a-F5506/SK1665': ['China', 'Taiwan', 'Vietnam'],\n",
    "        'O2a1c1a1a1a1g': ['Vietnam', 'China', 'Taiwan'],\n",
    "        'R1b1a2a1a1d1': ['France', 'Spain', 'United Kingdom'],\n",
    "        'R1b1a2a1a2b1b': ['Ireland', 'United Kingdom', 'United States'],\n",
    "        'LT': ['India', 'Iran', 'Turkey'],\n",
    "        'C2b*': ['Mongolia', 'Russia', 'United States'],\n",
    "        'A00b': ['Cameroon'],\n",
    "        'O1b1a1a2a-F5506/SK1661': ['China', 'Taiwan', 'Vietnam'],\n",
    "        'D1a1a2-F1070': ['China', 'Tibet', 'Kazakhstan'],\n",
    "        'BT': ['Nigeria', 'Saudi Arabia', 'India']\n",
    "    }\n",
    "\n",
    "    # Creating a dictionary to accumulate the predictions for each country\n",
    "    country_predictions = {}\n",
    "    for haplogroup, regions in haplogroup_regions.items():\n",
    "        prediction = predictions[haplogroups.index(haplogroup)]\n",
    "        for country in regions:\n",
    "            if country in country_predictions:\n",
    "                country_predictions[country] += prediction\n",
    "            else:\n",
    "                country_predictions[country] = prediction\n",
    "\n",
    "    # Load the world map\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "    # Add prediction data to the world map\n",
    "    world['Prediction'] = world['name'].map(country_predictions).fillna(0)\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    world.plot(column='Prediction', cmap='Reds', legend=True, edgecolor='black')\n",
    "    plt.title('Predicted Regions of Y-Chromosome Origin')\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    prompt = prompt1 + \"\\n\" + prompt2\n",
    "\n",
    "    client = OpenAI(api_key=apikey)\n",
    "\n",
    "    empty_thread = client.beta.threads.create()\n",
    "    thread_id = empty_thread.id\n",
    "\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=prompt,\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=\"asst_TlcrQ3mlz8Vzf0pr9gTGc50M\",\n",
    "    )\n",
    "    run_id = run.id\n",
    "\n",
    "    run_retrieve = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run_id,\n",
    "    )\n",
    "\n",
    "    run_retrieve = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run_id,\n",
    "    )\n",
    "    \n",
    "    while run_retrieve.status !=\"completed\":\n",
    "        run_retrieve = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run_id,\n",
    "        )\n",
    "\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread_id\n",
    "    )\n",
    "        \n",
    "    print(messages.data)\n",
    "    \n",
    "    file_id = messages.data[0].content[0].image_file.file_id\n",
    "\n",
    "    text_ = messages.data[0].content[1].text.value\n",
    "       \n",
    "    client = OpenAI(api_key=apikey)\n",
    "\n",
    "    image_data = client.files.content(file_id)\n",
    "    image_data_bytes = image_data.read()\n",
    "\n",
    "    with open(f\"{file_id}.png\", \"wb\") as file:\n",
    "        file.write(image_data_bytes)\n",
    "\n",
    "    plt.title(\"Haplogroup Region World Map\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    image = mpimg.imread(f\"{file_id}.png\")\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "    print(text_)\n",
    "    \n",
    "    return messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd546b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
